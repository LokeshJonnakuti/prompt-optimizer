[2023-05-16 11:28:59,318] [registry.py:249] Loading registry from /Users/v/Documents/PromptOptimizerProj/evals/evals/registry/evals
[2023-05-16 11:28:59,506] [registry.py:249] Loading registry from /Users/v/.evals/evals
[2023-05-16 11:28:59,506] [oaieval.py:110] [1;35mRun started: 230516182859HQ5ZZMAM[0m
[2023-05-16 11:28:59,507] [data.py:75] Fetching /Users/v/Documents/PromptOptimizerProj/evals/evals/registry/data/logiqa/temp.jsonl
[2023-05-16 11:28:59,508] [eval.py:34] Evaluating 100 samples
[2023-05-16 11:28:59,514] [eval.py:153] Running in threaded mode with 10 threads!
[2023-05-16 11:29:13,557] [record.py:330] Logged 100 rows of events to results/Entropy_Optim_p_0.05.jsonl: insert_time=22.180ms
[2023-05-16 11:29:42,311] [_common.py:105] Backing off openai_chat_completion_create_retrying(...) for 0.8s (openai.error.RateLimitError: That model is currently overloaded with other requests. You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 968b7b0afbc5d72c1023b3471710936b in your message.))
[2023-05-16 11:29:44,788] [record.py:330] Logged 100 rows of events to results/Entropy_Optim_p_0.05.jsonl: insert_time=22.965ms
[2023-05-16 11:29:44,795] [record.py:341] Final report: {'accuracy': 0.3}. Logged to results/Entropy_Optim_p_0.05.jsonl
[2023-05-16 11:29:44,795] [oaieval.py:147] Final report:
[2023-05-16 11:29:44,795] [oaieval.py:149] accuracy: 0.3
